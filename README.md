# ğŸ§  Hands-On Large Language Models  
### Learning & Code Companion

This repository documents my **end-to-end learning journey through the book**  
**_Hands-On Large Language Models: Language Understanding and Generation_ (Oâ€™Reilly)**,  
with full code implementations, experiments, notes, and practical extensions.

This is not just a reproduction of the bookâ€™s material.  
It is a hands-on engineering project focused on:
- deep understanding of modern LLM systems,
- building everything from scratch,
- experimenting beyond textbook examples, and
- creating reusable components for real-world applications.

---

## ğŸ“š Learning Coverage

### **Part I â€” Understanding Language Models**
- Introduction to Large Language Models  
- Representing Language & Embeddings  
- Attention & Transformer Architectures  
- Encoder-Only and Decoder-Only Models  
- Training Paradigms of LLMs  
- Responsible LLM Development  

### **Part II â€” Using Pretrained Language Models**
- Text Classification  
- Clustering & Topic Modeling  
- Prompt Engineering  
- Advanced Text Generation  
- Memory & Agent Systems  
- Semantic Search & RAG  
- Multimodal Language Models  

### **Part III â€” Training & Fine-Tuning Language Models**
- Training Embedding Models  
- Contrastive Learning & SBERT  
- Fine-Tuning BERT  
- Generative Model Fine-Tuning  
- PEFT, LoRA & Quantization  
- RLHF & Preference Optimization  

---

## ğŸ—‚ï¸ Repository Structure

```text
hands-on-llms/
â”‚
â”œâ”€â”€ 01_understanding_language_models/
â”‚   â”œâ”€â”€ introduction_to_llms.ipynb
â”‚   â”œâ”€â”€ embeddings_and_attention.ipynb
â”‚   â”œâ”€â”€ transformer_architectures.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 02_tokens_and_embeddings/
â”‚   â”œâ”€â”€ tokenization_experiments.ipynb
â”‚   â”œâ”€â”€ word_vs_subword.ipynb
â”‚   â”œâ”€â”€ contextual_embeddings.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 03_inside_transformers/
â”‚   â”œâ”€â”€ forward_pass.ipynb
â”‚   â”œâ”€â”€ attention_mechanisms.ipynb
â”‚   â”œâ”€â”€ caching_and_speedup.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 04_text_classification/
â”‚   â”œâ”€â”€ sentiment_analysis.ipynb
â”‚   â”œâ”€â”€ embedding_based_classification.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 05_clustering_and_topic_modeling/
â”‚   â”œâ”€â”€ text_clustering_pipeline.ipynb
â”‚   â”œâ”€â”€ bertopic.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 06_prompt_engineering/
â”‚   â”œâ”€â”€ prompting_strategies.ipynb
â”‚   â”œâ”€â”€ chain_of_thought.ipynb
â”‚   â”œâ”€â”€ tree_of_thought.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 07_advanced_text_generation/
â”‚   â”œâ”€â”€ langchain_chains.ipynb
â”‚   â”œâ”€â”€ memory_and_agents.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 08_semantic_search_and_rag/
â”‚   â”œâ”€â”€ vector_search.ipynb
â”‚   â”œâ”€â”€ rag_pipeline.ipynb
â”‚   â”œâ”€â”€ rag_evaluation.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 09_multimodal_models/
â”‚   â”œâ”€â”€ clip_and_embeddings.ipynb
â”‚   â”œâ”€â”€ image_captioning.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 10_training_and_finetuning/
â”‚   â”œâ”€â”€ embedding_training.ipynb
â”‚   â”œâ”€â”€ sbert_and_contrastive.ipynb
â”‚   â”œâ”€â”€ finetuning_bert.ipynb
â”‚   â”œâ”€â”€ peft_and_lora.ipynb
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ datasets/
â”œâ”€â”€ experiments/
â”œâ”€â”€ utils/
â””â”€â”€ README.md
